# -*- coding: utf-8 -*-
"""Copie de CNNPIERRE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fZ7XQaOC4bdm_paRcyPM5c0xYxWI4ciA

https://www.kaggle.com/code/purvanshsingh/keras-tuner-with-dataimagegenerator/notebook
https://codelabs.developers.google.com/codelabs/keras-flowers-squeezenet#3
"""

!pip install --upgrade --no-cache-dir gdown
!gdown 1Srhsx2y5Yhuia7FPVqhdhpIAJNE4Kv0W
!pip install -U keras-tuner
!unzip MIT_small_train_1.zip
!pip install optuna
!pip install -U kaleido

import numpy as np
import tensorflow as tf
import os
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import load_model
import optuna
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential,Model
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Flatten, Reshape
from tensorflow.keras.layers import MaxPool2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import plot_model
from tensorflow.keras.activations import softmax, softplus, softsign, relu, tanh, sigmoid, hard_sigmoid, linear
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt

train_data_dir = "/content/MIT_small_train_1/train"
test_data_dir = "/content/MIT_small_train_1/test"
MODEL_FNAME = "model_trained.h5"
folderHyper = "findHypers/"

img_width = 32
img_height= 32
validation_samples=2288

block = [True, False]
batch_sizes = [8, 16, 32, 64, 128]
number_of_epochs = [10, 50, 100]
optimizersIndex = ["SGD", "RMSprop", "Adagrad", "Adadelta", "Adam", "Adamax", "Nadam"]
learning_rates = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]
momentums = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]
activationsIndex = ["softmax", "softplus", "softsign", "relu", "tanh", 
                    "sigmoid", "hard_sigmoid", "Linear"]
activations = {"softmax": softmax, "softplus": softplus, 
               "softsign": softsign, "relu": relu, "tanh": tanh, 
               "sigmoid": sigmoid, "hard_sigmoid": hard_sigmoid, 
               "Linear": linear}
data_augmentations = {"width_shift_range": [0.1, 0], "height_shift_range": [0.1, 0], 
                      "horizontal_flip": [True, False], "vertical_flip": [True, False],
                      "rotation_range": [10,0], "brightness_range": [True, False],
                      "zoom_range": [0.1, 0], "shear_range": [10, 0]}

bnmomemtum=0.9
def fire(x, squeeze, expand, activation):
  y  = tf.keras.layers.Conv2D(filters=squeeze, kernel_size=1, activation= activation, padding='same')(x)
  y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)
  y1 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=1, activation= activation, padding='same')(y)
  y1 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y1)
  y3 = tf.keras.layers.Conv2D(filters=expand//2, kernel_size=3, activation= activation, padding='same')(y)
  y3 = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y3)
  return tf.keras.layers.concatenate([y1, y3])

def fire_module(squeeze, expand, activation):
  return lambda x: fire(x, squeeze, expand, activation)

def model(trial):

  # Choose hyperparameters
  first_block = trial.suggest_categorical("first_block", block)
  second_block = trial.suggest_categorical("second_block", block)
  third_block = trial.suggest_categorical("third_block", block)
  fourth_block = trial.suggest_categorical("fourth_block", block)
  batch_size = trial.suggest_categorical("batch_size", batch_sizes)
  number_of_epoch = trial.suggest_categorical("epochs", number_of_epochs)
  optimizerIndex = trial.suggest_categorical("optimizer", optimizersIndex)
  learning_rate = trial.suggest_categorical("learning_rate", learning_rates)
  activationIndex = trial.suggest_categorical("activation", activationsIndex)
  activation = activations[activationIndex]

  width_shift_range = trial.suggest_categorical("width_shift_range", data_augmentations["width_shift_range"])
  height_shift_range = trial.suggest_categorical("height_shift_range", data_augmentations["height_shift_range"])
  horizontal_flip = trial.suggest_categorical("horizontal_flip", data_augmentations["horizontal_flip"])
  vertical_flip = trial.suggest_categorical("vertical_flip", data_augmentations["vertical_flip"])
  rotation_range = trial.suggest_categorical("rotation_range", data_augmentations["rotation_range"])
  brightness_range = trial.suggest_categorical("brightness_range", data_augmentations["brightness_range"])
  if brightness_range:
      brightness_range = [0.8,1.2]
  else:
      brightness_range = [1.,1.]
  zoom_range = trial.suggest_categorical("zoom_range", data_augmentations["zoom_range"])
  shear_range = trial.suggest_categorical("shear_range", data_augmentations["shear_range"])

  
  x = tf.keras.layers.Input(shape=[img_width, img_height, 3]) 
  x = tf.keras.layers.Reshape((img_width, img_height, 3))(x)

  y = tf.keras.layers.Conv2D(kernel_size=3, filters=32, padding='same', use_bias=True, activation= activation)(x)

  y = tf.keras.layers.BatchNormalization(momentum=bnmomemtum)(y)

  if first_block == True:
    y = fire_module(24, 48, activation)(y)
    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)

  if second_block == True:
    y = fire_module(48, 96, activation)(y)
    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)

  if third_block == True:
    y = fire_module(64, 128, activation)(y)
    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)

  if fourth_block == True:
    y = fire_module(48, 96, activation)(y)
    y = tf.keras.layers.MaxPooling2D(pool_size=2)(y)

  y = fire_module(24, 48, activation)(y)
  y = tf.keras.layers.GlobalAveragePooling2D()(y)

  y = tf.keras.layers.Dense(8, activation= activation)(y)

  model = tf.keras.Model(x, y)

  model.compile(
    optimizer= optimizerIndex,
    loss= 'categorical_crossentropy',
    metrics=['accuracy'])
  
  model.summary()

  datagenTrain = ImageDataGenerator(
      rescale = 1.0/255,
      featurewise_center=False,
      samplewise_center=False,
      featurewise_std_normalization=False,
      samplewise_std_normalization=False,
      rotation_range=rotation_range,
      width_shift_range=width_shift_range,
      height_shift_range=height_shift_range,
      shear_range=shear_range,
      zoom_range=zoom_range,
      brightness_range= brightness_range,
      channel_shift_range=0.,
      fill_mode='nearest',
      cval=0.,
      horizontal_flip=horizontal_flip,
      vertical_flip=vertical_flip,
      )
  
  datagenTest = ImageDataGenerator(
      rescale = 1.0/255,
      featurewise_center=False,
      samplewise_center=False,
      featurewise_std_normalization=False,
      samplewise_std_normalization=False,
      rotation_range=0.,
      width_shift_range=0.,
      height_shift_range=0.,
      shear_range=0.,
      zoom_range=0.,
      channel_shift_range=0.,
      fill_mode='nearest',
      cval=0.,
      horizontal_flip=False,
      vertical_flip=False,
      )
  
  train_generator = datagenTrain.flow_from_directory(train_data_dir,
          target_size=(img_width, img_height),
          batch_size=batch_size,
          class_mode='categorical')
  
  test_generator = datagenTest.flow_from_directory(test_data_dir,
          target_size=(img_width, img_height),
          batch_size=batch_size,
          class_mode='categorical')

  # To save the best model
  checkpointer = ModelCheckpoint(filepath=MODEL_FNAME, verbose=1, save_best_only=True, 
                                  monitor='val_accuracy')
  
  history=model.fit(train_generator,
          steps_per_epoch=(int(np.ceil(400/batch_size))),
          epochs=number_of_epoch,
          validation_data=test_generator,
          validation_steps= (int(np.ceil(validation_samples/batch_size))), callbacks=[checkpointer])
  
  result = model.evaluate(test_generator)
  
  newFolder = folderHyper + "trial" + str(trial.number) + "/"
  if not os.path.exists(newFolder):
      os.makedirs(newFolder)
  model.save(newFolder + MODEL_FNAME)

  # Save results
  file  = open(newFolder + "results.txt", "w")
  file.write(f"Score: {result}\n")
  file.write(f"Batch size: {batch_size}\n")
  file.write(f"Epochs: {number_of_epoch}\n")
  file.write(f"Optimizer: {optimizerIndex}\n")
  file.write(f"Lr: {learning_rate}\n")
  if optimizerIndex == "SGD" or optimizerIndex == "RMSprop":
      file.write(f"Momentum: {bnmomemtum}\n")
  file.write(f"Activation: {activationIndex}\n")
  file.write(f"first_block: {first_block}\n")
  file.write(f"second_block: {second_block}\n")
  file.write(f"third_block: {third_block}\n")
  file.write(f"fourth_block: {fourth_block}\n")
  file.write("DATA AUGMENTATION: \n")
  file.write(f"width_shift_range: {width_shift_range}\n")
  file.write(f"height_shift_range: {height_shift_range}\n")
  file.write(f"horizontal_flip: {horizontal_flip}\n")
  file.write(f"vertical_flip: {vertical_flip}\n")
  file.write(f"rotation_range: {rotation_range}\n")
  file.write(f"brightness_range: {brightness_range}\n")
  file.write(f"zoom_range: {zoom_range}\n")
  file.write(f"shear_range: {shear_range}\n")
  file.close()
  
  fig1, ax1 = plt.subplots()
  ax1.plot(history.history['accuracy'])
  ax1.plot(history.history['val_accuracy'])
  ax1.set_title('model accuracy')
  ax1.set_ylabel('accuracy')
  ax1.set_xlabel('epoch')
  ax1.legend(['train', 'validation'], loc='upper left')
  fig1.savefig(newFolder + 'accuracy.jpg')
  plt.close(fig1)
    # summarize history for loss
  fig1, ax1 = plt.subplots()
  ax1.plot(history.history['loss'])
  ax1.plot(history.history['val_loss'])
  ax1.set_title('model loss')
  ax1.set_ylabel('loss')
  ax1.set_xlabel('epoch')
  ax1.legend(['train', 'validation'], loc='upper left')
  fig1.savefig(newFolder + 'loss.jpg')
    
  plot_model(model, to_file=newFolder + 'mymodel.png', show_shapes=True, show_layer_names=True)

  return result[1]

# Create Study object
study = optuna.create_study(direction="maximize")
# Optimize the study
study.optimize(model, n_trials=5) # Use more 
# Print the result
best_params = study.best_params
best_score = study.best_value
print(f"Best score: {best_score}\n")
print(f"Optimized parameters: {best_params}\n")

# Create Study object
study = optuna.create_study(direction="maximize")
# Optimize the study
study.optimize(model, n_trials=10) # Use more 
# Print the result
best_params = study.best_params
best_score = study.best_value
print(f"Best score: {best_score}\n")
print(f"Optimized parameters: {best_params}\n")

# plots
fig = optuna.visualization.plot_slice(study, params=['batch_size', 'epochs', 'optimizer', 
                                                     'learning_rate', "activation", "first_block"
                                                     ,"second_block", "third_block", "fourth_block"])
fig.write_image("plot_slice.png")
fig = optuna.visualization.plot_slice(study, params=['width_shift_range', 'height_shift_range', 'horizontal_flip', 
                                                     'vertical_flip', "rotation_range", "brightness_range",
                                                     "zoom_range", "shear_range"])
fig.write_image("plot_slice2.png")
fig = optuna.visualization.plot_contour(study, params=['batch_size', 'epochs', 'optimizer', 
                                                     'learning_rate', "activation", "first_block"
                                                     ,"second_block", "third_block", "fourth_block"])
fig.write_image("plot_contour.png")
fig = optuna.visualization.plot_contour(study, params=['width_shift_range', 'height_shift_range', 'horizontal_flip', 
                                                     'vertical_flip', "rotation_range", "brightness_range",
                                                     "zoom_range", "shear_range"])
fig.write_image("plot_contour2.png")
# Save results
file  = open("results.txt", "w")
file.write(f"Best score: {best_score}\n")
file.write(f"Optimized parameters: {best_params}\n")
file.close()

!zip -r /content/sample_data.zip /content/findHypers